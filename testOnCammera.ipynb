{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocessing(img):\n",
    "    mean=[0.485, 0.456, 0.406]\n",
    "    std=[0.229, 0.224, 0.225]\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255.0\n",
    "    for i in range(3):\n",
    "        img[:, :, i] = (img[:, :, i] - mean[i]) / std[i]\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_camera(onnx_model_path,n_fps_pred=8,n_frames_pred=10,n_frames_split=2):\n",
    "    #loader model\n",
    "    \n",
    "    session = ort.InferenceSession(onnx_model_path)\n",
    "    input_name=session.get_inputs()[0].name\n",
    "    output_name=session.get_outputs()[0].name\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "    fps=cap.get(cv2.CAP_PROP_FPS)\n",
    "    interval=int(fps/n_fps_pred)\n",
    "    X=[]\n",
    "    violent_frames=[]\n",
    "    tmp_violent_frames=[]\n",
    "    counts=0\n",
    "    while True:\n",
    "        counts+=1\n",
    "        ret,frame=cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if(counts%interval==0):\n",
    "            counts=0\n",
    "            processed_frame=img_preprocessing(frame)\n",
    "            X.append(processed_frame)\n",
    "            tmp_violent_frames.append(frame)\n",
    "        input_data=np.array([X.copy()],dtype=np.float32)\n",
    "        if(len(input_data[0])!=n_frames_pred):\n",
    "            pass\n",
    "        else:\n",
    "            outputs = session.run([output_name], {input_name: input_data})\n",
    "            y_preds=np.argmax(outputs[0],axis=1)[0]\n",
    "            # print(outputs[0][0])\n",
    "            if(y_preds==1):\n",
    "                if(len(violent_frames)>=n_frames_pred):\n",
    "                    violent_frames.extend(tmp_violent_frames[-(n_frames_pred-int(n_frames_pred/n_frames_split)+1):])\n",
    "                else:\n",
    "                    violent_frames.extend(tmp_violent_frames)\n",
    "                print(y_preds)\n",
    "            X=X[-int(n_frames_pred/n_frames_split)+1:]\n",
    "            tmp_violent_frames=tmp_violent_frames[-int(n_frames_pred/n_frames_split)+1:]\n",
    "        cv2.imshow('Video',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        if not ret:\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return violent_frames\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.27917325 -0.48206955]\n",
      "[ 1.1513852 -1.3709694]\n",
      "[ 1.5113578 -1.7062737]\n",
      "[ 1.4785805 -1.6747795]\n",
      "[ 1.3493472 -1.5530142]\n",
      "[ 0.86714095 -1.0771154 ]\n",
      "[ 1.0036818 -1.221785 ]\n",
      "[ 0.74582344 -0.96762097]\n",
      "[ 0.31880853 -0.53091383]\n",
      "[ 0.69210863 -0.91586554]\n",
      "[ 0.7024844 -0.9221374]\n",
      "[ 0.4756031 -0.6965579]\n",
      "[ 0.70657545 -0.9341739 ]\n",
      "[ 0.77434903 -0.9918822 ]\n",
      "[ 0.33630836 -0.5514173 ]\n",
      "[ 0.93896747 -1.1756968 ]\n",
      "[ 1.8404858 -2.0027797]\n",
      "[ 1.869554 -2.024868]\n",
      "[ 1.2074715 -1.4186431]\n",
      "[ 1.1257341 -1.3449188]\n",
      "[ 1.3098286 -1.5146344]\n",
      "[ 1.1956403 -1.4093943]\n",
      "[ 0.30057934 -0.50598514]\n",
      "[ 0.15725648 -0.34780037]\n",
      "[ 0.5598162 -0.7809422]\n",
      "[ 1.0064735 -1.2178031]\n"
     ]
    }
   ],
   "source": [
    "violentFrames=predict_on_camera(onnx_model_path=r'D:\\DS\\ViolenceDetection\\notebooks\\model_quantized.onnx',n_fps_pred=8,n_frames_pred=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('array.npy', violentFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(violentFrames).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(violentFrames)):\n",
    "    # Show each frame\n",
    "    # if(i>=12):\n",
    "\n",
    "    cv2.imshow('Video Frame', violentFrames[min(len(violentFrames)-1,i+11)])\n",
    "    # else:\n",
    "    #     cv2.imshow('Video Frame', violentFrames[i])\n",
    "    \n",
    "    # Wait for 25 ms between frames (40 FPS). Adjust as needed.\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break  # Press 'q' to exit early\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
